{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UL7x05VftanaDdXI_FSfomuhasQfhiSf",
      "authorship_tag": "ABX9TyPZ7iPp2D+/ffWIhsb0fwC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RegNLP/GraphRAG4RegGraph/blob/main/RegSumDatasetSplit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkKoEyaLOt_C",
        "outputId": "5ee3bc70-c547-47e9-b434-0db798b4d7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split into 247 training, 53 validation, and 54 test items.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def split_json_data(input_file, train_file, validation_file, test_file, train_ratio=0.7, validation_ratio=0.15):\n",
        "    \"\"\"\n",
        "    Reads a JSON file, shuffles the data, splits it into training, validation, and test sets,\n",
        "    and writes each set to separate JSON files.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input JSON file.\n",
        "        train_file (str): Path for saving the training set.\n",
        "        validation_file (str): Path for saving the validation set.\n",
        "        test_file (str): Path for saving the test set.\n",
        "        train_ratio (float): Proportion of data to use for training.\n",
        "        validation_ratio (float): Proportion of data to use for validation.\n",
        "            The remainder will be used for testing.\n",
        "    \"\"\"\n",
        "    # Load the JSON data from the input file\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Shuffle the data to ensure random splitting\n",
        "    random.shuffle(data)\n",
        "\n",
        "    # Calculate split indices\n",
        "    total = len(data)\n",
        "    train_end = int(total * train_ratio)\n",
        "    validation_end = train_end + int(total * validation_ratio)\n",
        "\n",
        "    # Split the data\n",
        "    train_data = data[:train_end]\n",
        "    validation_data = data[train_end:validation_end]\n",
        "    test_data = data[validation_end:]\n",
        "\n",
        "    # Write the splits to separate JSON files\n",
        "    with open(train_file, 'w') as f:\n",
        "        json.dump(train_data, f, indent=4)\n",
        "\n",
        "    with open(validation_file, 'w') as f:\n",
        "        json.dump(validation_data, f, indent=4)\n",
        "\n",
        "    with open(test_file, 'w') as f:\n",
        "        json.dump(test_data, f, indent=4)\n",
        "\n",
        "    print(f\"Data split into {len(train_data)} training, {len(validation_data)} validation, and {len(test_data)} test items.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define file paths\n",
        "    input_json = '/content/drive/MyDrive/Colab Notebooks/ExtractedSummaries/summaries_content.json'\n",
        "    train_json = '/content/drive/MyDrive/Colab Notebooks/ExtractedSummaries/train_RegSum_Data.json'\n",
        "    validation_json = '/content/drive/MyDrive/Colab Notebooks/ExtractedSummaries/validation_RegSum_Data.json'\n",
        "    test_json = '/content/drive/MyDrive/Colab Notebooks/ExtractedSummaries/test_RegSum_Data.json'\n",
        "\n",
        "    # Call the function with default split ratios (70% train, 15% validation, 15% test)\n",
        "    split_json_data(input_json, train_json, validation_json, test_json)\n"
      ]
    }
  ]
}